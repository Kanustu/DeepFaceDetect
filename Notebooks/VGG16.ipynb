{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f9f68a2-e975-43b4-9565-2d7f2ddd3e5a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D, Dropout, Flatten, Dense, Input# Sequential model for building a linear stack of layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b5aa0ec-7a0e-43bf-821d-d4b4f4d5d243",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('/Users/jordankanius/LHL_projects/Face2Face_Real_vs_Fake/functions/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d28a859-a9bd-46d1-8791-8803e3eb0501",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from create_dataframe import create_df\n",
    "train_meta = create_df('train')\n",
    "valid_meta = create_df('valid')\n",
    "test_meta = create_df('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b99a99-8ea8-4ea7-966e-33d5c3c36a69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the base path where your image data is stored\n",
    "base_path = '../real_vs_fake/real-vs-fake/'\n",
    "\n",
    "# Create an ImageDataGenerator for image preprocessing and augmentation\n",
    "image_gen = ImageDataGenerator(rescale=1./255.)\n",
    "# The 'rescale' parameter normalizes pixel values to the range [0, 1] by dividing each pixel value by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a94679-73c9-4ce1-8805-d5ffa84cd8de",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "VGG16_train = image_gen.flow_from_directory(\n",
    "    base_path + 'train/',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=100,\n",
    "    class_mode='binary'\n",
    ")\n",
    "VGG16_valid = image_gen.flow_from_directory(\n",
    "    base_path + 'valid/',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=100,\n",
    "    class_mode='binary'\n",
    ")\n",
    "VGG16_test = image_gen.flow_from_directory(\n",
    "    base_path + 'test/',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=100,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee03ef0-815a-4c7c-8f9d-cfa9d27d55fd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84c9ed88-98bc-43f9-ae29-a8c5849f3b1b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 8, 8, 512)         14714688  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32768)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2097216   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,811,969\n",
      "Trainable params: 16,811,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (256, 256, 3)\n",
    "model = Sequential()\n",
    "model.add(Input(shape=input_shape))\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d239ad5-6592-4ed5-87c5-c0a27576294c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba3c2dcb-8c4a-494d-a886-65d9b6143d37",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 20:34:07.183211: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1/1000 [..............................] - ETA: 14:37:50 - loss: 0.7090 - accuracy: 0.5800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(VGG16_train, epochs= 10, validation_data=VGG16_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ava",
   "language": "python",
   "name": "ava"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
